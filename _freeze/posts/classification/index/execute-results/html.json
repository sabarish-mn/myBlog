{
  "hash": "683afcdd55b5668ee440359f59797704",
  "result": {
    "markdown": "---\ntitle: Classification\nauthor: Sabarish Muthumani Narayanasamy\ndate: '2023-11-15'\ncategories:\n  - code\n  - analysis\nimage: image.jpg\n---\n\n# Blog 3 â€“ Classification\n\n### Implementation of Isolation Forest to Detect Outliers in Python (Scikit-learn)\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n```\n:::\n\n\n### Diabetes and Pima Indian Dataset\n1. Machine learning has become an important approach to many researches today. It is a field of artificial intelligence and its importance is increasing day by day.\n\n2. In this project, a classification model will be made using the Pima Indians Diabetes data set. Diabetes is a group of metabolic disorders in which long-term high blood sugar levels are seen. High blood sugar symptoms include frequent urination, increased thirst, and increased hunger. If left untreated, diabetes can cause many complications. Acute complications may include diabetic ketoacidosis, hyperosmolar hyperglycemic state, or death. Serious long-term complications include cardiovascular disease, stroke, chronic kidney disease, foot ulcer, and eye damage.\n\n3. This dataset was originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The purpose of the dataset is to diagnostically predict whether a patient has diabetes based on the specific diagnostic measures included in the data set. Various restrictions have been imposed on the selection of these samples from a larger database.\n\n4. In particular, all the patients here are women who are at least 21 years old of Pima Indian heritage. The data set consists of 768 observation units and 9 variables. These variables are; pregnancy, glucose, blood pressure, skin thickness, insulin, body mass index, diabetes pedigree, age and outcome. After the exploratory data analysis on the data set is completed, the machine learning model will be set up. For this, supervised learning algorithms will be used.\n\n### Importing Libraries\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV, RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, roc_auc_score, recall_score, f1_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n```\n:::\n\n\n### Reading Data\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndiabetes = pd.read_csv(\"diabetes.csv\")\ndf = diabetes.copy()\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndf.describe().T\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Pregnancies</th>\n      <td>768.0</td>\n      <td>3.845052</td>\n      <td>3.369578</td>\n      <td>0.000</td>\n      <td>1.00000</td>\n      <td>3.0000</td>\n      <td>6.00000</td>\n      <td>17.00</td>\n    </tr>\n    <tr>\n      <th>Glucose</th>\n      <td>768.0</td>\n      <td>120.894531</td>\n      <td>31.972618</td>\n      <td>0.000</td>\n      <td>99.00000</td>\n      <td>117.0000</td>\n      <td>140.25000</td>\n      <td>199.00</td>\n    </tr>\n    <tr>\n      <th>BloodPressure</th>\n      <td>768.0</td>\n      <td>69.105469</td>\n      <td>19.355807</td>\n      <td>0.000</td>\n      <td>62.00000</td>\n      <td>72.0000</td>\n      <td>80.00000</td>\n      <td>122.00</td>\n    </tr>\n    <tr>\n      <th>SkinThickness</th>\n      <td>768.0</td>\n      <td>20.536458</td>\n      <td>15.952218</td>\n      <td>0.000</td>\n      <td>0.00000</td>\n      <td>23.0000</td>\n      <td>32.00000</td>\n      <td>99.00</td>\n    </tr>\n    <tr>\n      <th>Insulin</th>\n      <td>768.0</td>\n      <td>79.799479</td>\n      <td>115.244002</td>\n      <td>0.000</td>\n      <td>0.00000</td>\n      <td>30.5000</td>\n      <td>127.25000</td>\n      <td>846.00</td>\n    </tr>\n    <tr>\n      <th>BMI</th>\n      <td>768.0</td>\n      <td>31.992578</td>\n      <td>7.884160</td>\n      <td>0.000</td>\n      <td>27.30000</td>\n      <td>32.0000</td>\n      <td>36.60000</td>\n      <td>67.10</td>\n    </tr>\n    <tr>\n      <th>DiabetesPedigreeFunction</th>\n      <td>768.0</td>\n      <td>0.471876</td>\n      <td>0.331329</td>\n      <td>0.078</td>\n      <td>0.24375</td>\n      <td>0.3725</td>\n      <td>0.62625</td>\n      <td>2.42</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>768.0</td>\n      <td>33.240885</td>\n      <td>11.760232</td>\n      <td>21.000</td>\n      <td>24.00000</td>\n      <td>29.0000</td>\n      <td>41.00000</td>\n      <td>81.00</td>\n    </tr>\n    <tr>\n      <th>Outcome</th>\n      <td>768.0</td>\n      <td>0.348958</td>\n      <td>0.476951</td>\n      <td>0.000</td>\n      <td>0.00000</td>\n      <td>0.0000</td>\n      <td>1.00000</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIn this dataset missing data are filled with 0. First, we are gonna change zeros with NaN\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness',\n                                                                      'Insulin','BMI']].replace(0, np.NaN)\n```\n:::\n\n\n### Data Visualization\n\n#### Histogram\nA histogram is a bar graph representation of a grouped data distribution. In other words, it is the transfer of data consisting of repetitive numbers to the table first, and to the chart by using the table, in other words, the graph of the data groups is displayed in rectangular columns.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndf.hist(bins=20,figsize = (15,15));\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=1170 height=1170}\n:::\n:::\n\n\n#### Countplot and PiePlot\nA count plot can be thought of as a histogram across a categorical, instead of quantitative, variable. A Pie Chart is a type of graph that displays data in a circular graph. The pieces of the graph are proportional to the fraction of the whole in each category.\n\nWe examined distribution of outcome with countplot and pieplot.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nplt.title(\"Distribution of Outcome\")\nsns.countplot(df[\"Outcome\"], saturation=1)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n<Axes: title={'center': 'Distribution of Outcome'}, ylabel='count'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-2.png){width=601 height=431}\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndef PlotPie(df, nameOfFeature):\n    labels = [str(df[nameOfFeature].unique()[i]) for i in range(df[nameOfFeature].nunique())]\n    values = [df[nameOfFeature].value_counts()[i] for i in range(df[nameOfFeature].nunique())]\n\n    trace=go.Pie(labels=labels,values=values)\n\n    py.iplot([trace])\n\nPlotPie(df, \"Outcome\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>                            <div id=\"246cc3b0-9a67-494d-82d5-546b5ee449dd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"246cc3b0-9a67-494d-82d5-546b5ee449dd\")) {                    Plotly.newPlot(                        \"246cc3b0-9a67-494d-82d5-546b5ee449dd\",                        [{\"labels\":[\"1\",\"0\"],\"values\":[500,268],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('246cc3b0-9a67-494d-82d5-546b5ee449dd');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>\n```\n:::\n:::\n\n\n#### Correlation\nCorrelation is a term that is a measure of the strength of a linear relationship between two quantitative variables.\n\nIn this graph, there are correlations of all variables with the Outcome variable.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef corr_to_target(dataframe, target, title=None, file=None):\n    plt.figure(figsize=(4,6))\n    sns.heatmap(dataframe.corr()[[target]].sort_values(target,\n                                                        ascending=False)[1:],\n                                                        annot=True,\n                                                        cmap='coolwarm')\n    \n    plt.title(f'\\n{title}\\n', fontsize=18)\n    \n    plt.show();\n    \n    return\n\ncorr_to_target(df, \"Outcome\", title=\"Outcome\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=516 height=566}\n:::\n:::\n\n\nCorrelation matrix of variables with each other.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ncorr_matrix = df.corr()\nsns.clustermap(corr_matrix, annot=True, fmt=\".2f\")\nplt.title(\"Correlation Between Features\")\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\nText(0.5, 1.0, 'Correlation Between Features')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-2.png){width=1038 height=964}\n:::\n:::\n\n\n### Splitting Train and Test Set\nAbove, we first gave all variables except the \"outcome\" variable to the X variable and gave the variable \"outcome\" to the y variable. Then we split the data into train and test data. X_train and y_train show the dependent and independent variables to be used to test the model, while X_test and y_test are used to develop the model. Test_size specifies how many% of data (30%) will be used for testing. Random_state is used to see the same distinction every time we run the program. Stratify provides a balanced separation of classes in the y variable when separating.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n#y = df[\"Outcome\"]\n#X = df.drop([\"Outcome\"], axis = 1)\ntrain,test = train_test_split(df, test_size=0.3, random_state = 2)\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ntrain.isnull().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\nPregnancies                   0\nGlucose                       2\nBloodPressure                22\nSkinThickness               162\nInsulin                     256\nBMI                           7\nDiabetesPedigreeFunction      0\nAge                           0\nOutcome                       0\ndtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ntest.isnull().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nPregnancies                   0\nGlucose                       3\nBloodPressure                13\nSkinThickness                65\nInsulin                     118\nBMI                           4\nDiabetesPedigreeFunction      0\nAge                           0\nOutcome                       0\ndtype: int64\n```\n:::\n:::\n\n\n### Handling with Missing Values\n\nAfter filling the 0s with the value of NaN, the missing values â€‹â€‹will be visualized. We use the missingno library for this.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nmsno.bar(df,figsize=(10,6))\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n<Axes: >\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-2.png){width=878 height=737}\n:::\n:::\n\n\nWe will fill in each missing value with its median value.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ndef median_target(dataf, var):   \n    temp = dataf[dataf[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp\n```\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ncolumns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age']\nfor i in columns:\n    train.loc[(train['Outcome'] == 0 ) & (train[i].isnull()), i] = median_target(train,i)[i][0]\n    train.loc[(train['Outcome'] == 1 ) & (train[i].isnull()), i] = median_target(train,i)[i][1]\n    \n    test.loc[(test['Outcome'] == 0 ) & (test[i].isnull()), i] = median_target(train,i)[i][0]\n    test.loc[(test['Outcome'] == 1 ) & (test[i].isnull()), i] = median_target(train,i)[i][1]\n```\n:::\n\n\nAfter filling if we examine null values in dataset, we will see there are not any missing values.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nprint(\"TRAIN DATA\")\nprint(train.isnull().sum(), \"\\n\")\nprint(\"TEST DATA\")\nprint(test.isnull().sum())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTRAIN DATA\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64 \n\nTEST DATA\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n```\n:::\n:::\n\n\n### Plotting Roc Curve\n\nROC curves are frequently used to show in a graphical way the connection/trade-off between clinical sensitivity and specificity for every possible cut-off for a test or a combination of tests. In addition the area under the ROC curve gives an idea about the benefit of using the test(s) in question.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0,1],[0,1],\"k--\")\n    plt.axis([0,1,0,1])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n```\n:::\n\n\n### Machine Learning\nWe will use 6 different machine learning algorithm for this model and examine ROC score, accuracy test and train score, best parameters and ROC curve\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nX_train = train.iloc[:,:8]\ny_train = train.iloc[:,-1:]\n\nX_test = test.iloc[:,:8]\ny_test = test.iloc[:,-1:]\n```\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\ndef ml_model(model, parameters):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\n    random_search = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1, verbose=1)\n    pipe = make_pipeline(StandardScaler(),random_search)\n    pipe.fit(X_train, y_train)\n    y_pred_proba = pipe.predict_proba(X_test)[:,1]\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n    print(\"ROC Score : \",roc_auc_score(y_test, y_pred_proba))\n    print(\"F1 score for train: \", f1_score(y_train, pipe.predict(X_train)))\n    print(\"F1 score for test: \" , f1_score(y_test, pipe.predict(X_test)))\n    print(\"Best params:\" + str(random_search.best_params_))\n    plot_roc_curve(fpr, tpr)\n    \nlog_reg_params = {\"C\" : [1,2,3,0.01,0.001, 2.5, 1.5],\n                  \"max_iter\" : range(100,800,100)}\nknn_params = {\"n_neighbors\" : np.arange(1,50),\n              \"leaf_size\" : np.arange(1,50)}\ndecTree_params = {\"max_depth\" : [5,10,15,20,25,30],\n                  \"min_samples_split\" : np.arange(2,50),\n                  \"min_samples_leaf\" : np.arange(1,50)}\nrandomForest_params = {\"n_estimators\" : [100,500, 1000],\n                       \"min_samples_split\" : np.arange(2,30),\n                       \"min_samples_leaf\" : np.arange(1,50),\n                       \"max_features\" : np.arange(1,7)}\nlgbm_params = {\"n_estimators\" : [100,500,1000],\n               \"subsample\" : [0.6,0.8,1.0],\n               \"max_depth\" : [5,10,15,20,25,30],\n               \"learning_rate\" : [0.1, 0.01, 0.02, 0.5],\n               \"min_child_samples\" : np.arange(2,30)}\n\nsgd_params = {\"alpha\" : [0.0001, 0.1, 0.001, 0.01],\n              \"max_iter\" : [100,500,1000,2000],\n              \"loss\" : [\"log\",\"modified_huber\",\"perceptron\"]}\n```\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nml_model(LogisticRegression(), log_reg_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting 100 folds for each of 10 candidates, totalling 1000 fits\nROC Score :  0.8506791171477079\nF1 score for train:  0.6523076923076924\nF1 score for test:  0.5573770491803278\nBest params:{'max_iter': 700, 'C': 0.01}\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-22-output-2.png){width=599 height=434}\n:::\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nml_model(KNeighborsClassifier(), knn_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting 100 folds for each of 10 candidates, totalling 1000 fits\nROC Score :  0.8732173174872666\nF1 score for train:  0.7647058823529411\nF1 score for test:  0.7007299270072993\nBest params:{'n_neighbors': 19, 'leaf_size': 23}\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-23-output-2.png){width=599 height=434}\n:::\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nml_model(DecisionTreeClassifier(), decTree_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting 100 folds for each of 10 candidates, totalling 1000 fits\nROC Score :  0.9217741935483872\nF1 score for train:  0.8385542168674699\nF1 score for test:  0.8104575163398693\nBest params:{'min_samples_split': 13, 'min_samples_leaf': 33, 'max_depth': 25}\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-24-output-2.png){width=599 height=434}\n:::\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nml_model(RandomForestClassifier(), randomForest_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting 100 folds for each of 10 candidates, totalling 1000 fits\nROC Score :  0.9337011884550086\nF1 score for train:  0.8733850129198966\nF1 score for test:  0.7857142857142857\nBest params:{'n_estimators': 1000, 'min_samples_split': 24, 'min_samples_leaf': 13, 'max_features': 2}\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-25-output-2.png){width=599 height=434}\n:::\n:::\n\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nml_model(LGBMClassifier(), lgbm_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting 100 folds for each of 10 candidates, totalling 1000 fits\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 192, number of negative: 345\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 620\n[LightGBM] [Info] Number of data points in the train set: 537, number of used features: 8\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.357542 -> initscore=-0.586049\n[LightGBM] [Info] Start training from score -0.586049\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\nROC Score :  0.9449066213921902\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\nF1 score for train:  0.907103825136612\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\nF1 score for test:  0.7851851851851851\nBest params:{'subsample': 1.0, 'n_estimators': 100, 'min_child_samples': 24, 'max_depth': 20, 'learning_rate': 0.02}\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-26-output-2.png){width=599 height=434}\n:::\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nml_model(SGDClassifier(), sgd_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting 100 folds for each of 10 candidates, totalling 1000 fits\nROC Score :  0.775\nF1 score for train:  0.5993690851735015\nF1 score for test:  0.5210084033613445\nBest params:{'max_iter': 2000, 'loss': 'modified_huber', 'alpha': 0.001}\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-27-output-2.png){width=599 height=434}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script type=\"text/javascript\">\nwindow.PlotlyConfig = {MathJaxConfig: 'local'};\nif (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\nif (typeof require !== 'undefined') {\nrequire.undef(\"plotly\");\nrequirejs.config({\n    paths: {\n        'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n    }\n});\nrequire(['plotly'], function(Plotly) {\n    window._Plotly = Plotly;\n});\n}\n</script>\n\n"
      ]
    }
  }
}